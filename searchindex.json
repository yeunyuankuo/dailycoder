{"categories":[{"title":"Container","uri":"https://yeunyuankuo.github.io/categories/container/"},{"title":"Git","uri":"https://yeunyuankuo.github.io/categories/git/"},{"title":"Github","uri":"https://yeunyuankuo.github.io/categories/github/"},{"title":"Go","uri":"https://yeunyuankuo.github.io/categories/go/"},{"title":"Interview","uri":"https://yeunyuankuo.github.io/categories/interview/"},{"title":"Step-by-Step Guide","uri":"https://yeunyuankuo.github.io/categories/step-by-step-guide/"},{"title":"Virtualization Technologies","uri":"https://yeunyuankuo.github.io/categories/virtualization-technologies/"}],"posts":[{"content":"1. Clone Target Repository Clone the remote repository code you want to your local environment. You can find the clone repo link inside the Code button drop-down.\ncd into the folder you want to clone the repository, then paste the HTTPS link and created a clone with the git clone command.\n$ git clone {HTTPS_LINK_HERE}  After running the git clone command, you should see a new folder with the target repo code inside.\n2. Create a New Branch Now cd into the new folder created by the git clone command, and let‚Äôs create a new branch by using the git branch command.\n$ git branch {NEW_BRANCH_NAME}  After you‚Äôve created the branch, use the following git commands to check if your new branch has been created, and then switch to your new branch.\n# check if {NEW_BRANCH_NAME} is listed locally as your branch $ git branch # switch to new branch $ git checkout {NEW_BRANCH_NAME}  3. Push New Branch to Repository We can push our new branch to the repository with the git push command. But here we also want to set the upstream branch. Every time a new branch is created, we need to set up an upstream branch so the new branch knows which remote repository to use every time it synchronizes its commit history. This step can be achieved with the --set-upstream command.\n$ git push --set-upstream origin {NEW_BRANCH_NAME}  If you didn‚Äôt set up an upstream branch and push your code, the following error code will show up. Thus, please remember to do this step before pushing your code from the new branch.\nfatal: The current branch has no upstream branch  After pushing your branch to the repository, you should see your branch show up on the branches drop-down list shown in the image below. 4. Push Code Changes Now you can push code changes into the new branch you‚Äôve just created!\n# Checkout your new branch # make changes to the code and push to new branch $ git add . $ git commit -m \u0026quot;new code commit here...\u0026quot; $ git push  Resources  https://opensource.com/article/19/7/create-pull-request-github https://www.geeksforgeeks.org/how-to-set-upstream-branch-on-git/   Thank you for reading! üåü If you find this article interesting feel free to leave a comment!\n","id":0,"section":"posts","summary":"1. Clone Target Repository Clone the remote repository code you want to your local environment. You can find the clone repo link inside the Code button drop-down.\ncd into the folder you want to clone the repository, then paste the HTTPS link and created a clone with the git clone command.\n$ git clone {HTTPS_LINK_HERE}  After running the git clone command, you should see a new folder with the target repo code inside.","tags":["Git","Github","branch","Step-by-Step Guide"],"title":"Step-by-Step Guide‚ÄîHow to create a new branch for Git repository","uri":"https://yeunyuankuo.github.io/2022/05/create_git_branch/","year":"2022"},{"content":" ‚ÄúAn important sign of Kubernetes momentum is the continuing shift to production, growing from 59% in the 2020 report to 65% this year. Companies with more than 500 developers were more likely to be running all or most containerized workloads in production (78%). In our first State of Kubernetes report in 2018, less than a third (30%) reported running Kubernetes in production.‚Äù\n‚Äî State of Kubernetes 2021 Report by VMware\n In VMware‚Äôs State of Kubernetes 2021 Report, it pointed out that there has been a distinct shift to Kubernetes in Production. More companies are choosing to run containerized workloads over other virtualization technologies like bare-metal servers and virtual machines.\nTo understand why companies favor containers over other virtualization technologies. We need to take a closer look at the 3 most common virtualization technologies on the market: Bare-metal Servers, Virtual Machines, and Containers.\nBare-metal Servers With bare-metal servers, the operating system is installed directly on the server, eliminating layers and delivering better performance. For instance, you simply install an operating system on your server hardware, then any shared libraries on top of that, and finally your application that uses those libraries, and you‚Äôd be good to go. This is how things have been for a long time.\nThe issue with this architecture is that is massively inefficient. Your hardware cost is the same whether you are running a 0% utilization or 100% utilization. All your applications are fighting for the same resources and you have to keep the versions of your library in sync with all the applications. If one program requires an updated version of the library that is incompatible with other applications operating on the same host, then you run into problems!\nVirtual Machines Virtual machine solves the problem of bare-metal server by putting a virtualization platform over the operating system. Now you‚Äôve isolated applications and their libraries with their own full operating system into a virtual machine. This enhances usage since you can run additional virtual machines on top of the existing hardware, lowering your physical footprint significantly.\nThe disadvantage of virtual machines is that the virtualization layer is cumbersome. In the image above, you now have 4 operating systems instead of one. That means more patching, more updates, and significantly more space being taken up by the physical host. There‚Äôs also significant redundancy. You‚Äôve installed potentially the same operating system 4 times and potentially the same library 3 times. We can do better!\nContainers By packaging code and dependencies together, containers are an abstraction for the application layer. The container runtime shares the operating system‚Äôs kernel, enabling you to create container images using file system layers. The containers are lightweight efficient and fast! Containers consume less space compared to virtual machines (container images usually take up around tens of MB in size). They can be spawned up and spawned down faster than virtual machines.\nContainers allow for better utilization of the underlying hardware. You can share libraries when necessary, but you can also isolate libraries for your applications. Containers are also highly portable. Because containers isolate software from the other layers, their codes run identically across different environments, whether it‚Äôs from compliance, staging, or all the way to production.\nSummary After understanding the differences between bare-metal servers, virtual machines, and containers, we can safely say that containers provide benefits that other virtualization technologies do not possess, such as faster software development cycles, increased resource utilization, and easier application upgrades.\nWhether your organization is one of the 65% that is already using containerized workload in production or not, the momentum behind container technology is evident!\nResources  State of Kubernetes 2021 Report ‚Äî VMware What is a Bare Metal Server? Docker Official Website   Thank you for reading! üåü If you find this article interesting feel free to leave a comment!\n","id":1,"section":"posts","summary":"‚ÄúAn important sign of Kubernetes momentum is the continuing shift to production, growing from 59% in the 2020 report to 65% this year. Companies with more than 500 developers were more likely to be running all or most containerized workloads in production (78%). In our first State of Kubernetes report in 2018, less than a third (30%) reported running Kubernetes in production.‚Äù\n‚Äî State of Kubernetes 2021 Report by VMware","tags":["Virtualization Technologies","Container","Virtual Machine","Bare-metal Server","Kubernetes"],"title":"Why is Containerization Taking Over?","uri":"https://yeunyuankuo.github.io/2022/04/container_taking_over/","year":"2022"},{"content":" I was asked this question in one of my recent software engineer job interviews, and I believe I didn‚Äôt answer it as well as I would have liked, so I wanted to write this blog to re-answer it and perhaps aid someone else who is also curious about the solution.\n In Go articles, we often see goroutine introduced as a lightweight thread. But why is it lightweight? how lightweight?\n Before we delve into the ‚Äúlightweight‚Äù part, we need to first understand the two components in this comparison equation ‚ÄîThread \u0026amp; Goroutine.\nWhat is a thread? In short, a thread is a basic unit of CPU utilization; it comprises a thread ID, a program counter, a register set, and a stack. It shares with other threads belonging to the same process its code section, data section, and other operating-system resources, such as open files and signals.\nWhat is a goroutine? In Go, a ‚Äúgo‚Äù statement starts the execution of a function call as an independent concurrent thread of control, or goroutine, within the same address space. The expression must be a function or method call; it cannot be parenthesized. Calls of built-in functions are restricted as for expression statements.\nfunc main() { go fmt.Println(\u0026quot;Hello from another goroutine\u0026quot;) fmt.Println(\u0026quot;Hello from the main goroutine\u0026quot;) // At this point the program execution stops and all // active goroutines are killed. }  The function value and parameters are evaluated as usual in the calling goroutine, but unlike with a regular call, program execution does not wait for the invoked function to complete. Instead, the function begins executing independently in a new goroutine. When the function terminates, its goroutine also terminates. If the function has any return values, they are discarded when the function completes.\nGoroutine vs. Thread Each operating system thread has a fixed-size block memory (sometimes as large as 2MB) for its stack, which is the work area where it saves the local variables of function calls that are in process or momentarily halted while another function is performed. This fixed-size stack is both too big and too small. A 2MB stack would be a tremendous waste of memory for a small goroutine that simply waits for a WaitGroup before closing a channel.\nIt is not uncommon for a Go program to generate hundreds of thousands of goroutines at once, which would be difficult to stack. Regardless of size, fixed-size stacks are not always large enough for the most complex and deeply recursive routines. Changing the fixed size can improve space efficiency and allow for the creation of more threads, or it can permit more deeply recursive algorithms, but not both.\nA goroutine, on the other hand, starts with a modest stack, typically 2KB. The stack of a goroutine, like the stack of an OS thread, maintains the local variable of active and suspended function calls, but unlike the stack of an OS thread, the stack of a goroutine is not fixed; it grows and shrinks as needed. A goroutine stack‚Äôs size limit could be as much as 1GB, which is orders of magnitude larger than a conventional fixed-size thread stack; however, few goroutines use that much.\nWrapping Up In Summary, to answer the question of why goroutine is called a lightweight thread. It‚Äôs because a goroutine starts with a stack space of 2KB which is extremely smaller and more compact than OS thread\u0026rsquo;s fixed-size stack space of 2MB. However, the goroutine‚Äôs stack space is growable and it can grow and exceed the OS thread‚Äôs 2MB fixed-stack size. So a goroutine is actually only ‚Äúlightweight‚Äù in the beginning and could gradually grow ‚Äúoverweight‚Äù when needed!\nResources  Official Go Specs The Go Programming Language ‚Äî Alan A. A. Donovan and Brian W. Kernighan Operating System Concepts ‚Äî Abraham Silberschatz, Greg Gagne, and Peter Baer Galvin Professor Dr. John Bell‚Äôs lecture notes for Operating Systems Goroutines are lightweight threads   Thank you for reading! üåü If you find this article interesting feel free to leave a comment!\n","id":2,"section":"posts","summary":"I was asked this question in one of my recent software engineer job interviews, and I believe I didn‚Äôt answer it as well as I would have liked, so I wanted to write this blog to re-answer it and perhaps aid someone else who is also curious about the solution.\n In Go articles, we often see goroutine introduced as a lightweight thread. But why is it lightweight? how lightweight?","tags":["Go","goroutine","lightweight","thread","Interview"],"title":"Why is goroutine being called a ‚Äúlightweight‚Äù thread?","uri":"https://yeunyuankuo.github.io/2022/03/goroutine-lightweight/","year":"2022"}],"tags":[{"title":"Bare-metal Server","uri":"https://yeunyuankuo.github.io/tags/bare-metal-server/"},{"title":"branch","uri":"https://yeunyuankuo.github.io/tags/branch/"},{"title":"Container","uri":"https://yeunyuankuo.github.io/tags/container/"},{"title":"Git","uri":"https://yeunyuankuo.github.io/tags/git/"},{"title":"Github","uri":"https://yeunyuankuo.github.io/tags/github/"},{"title":"Go","uri":"https://yeunyuankuo.github.io/tags/go/"},{"title":"goroutine","uri":"https://yeunyuankuo.github.io/tags/goroutine/"},{"title":"Interview","uri":"https://yeunyuankuo.github.io/tags/interview/"},{"title":"Kubernetes","uri":"https://yeunyuankuo.github.io/tags/kubernetes/"},{"title":"lightweight","uri":"https://yeunyuankuo.github.io/tags/lightweight/"},{"title":"Step-by-Step Guide","uri":"https://yeunyuankuo.github.io/tags/step-by-step-guide/"},{"title":"thread","uri":"https://yeunyuankuo.github.io/tags/thread/"},{"title":"Virtual Machine","uri":"https://yeunyuankuo.github.io/tags/virtual-machine/"},{"title":"Virtualization Technologies","uri":"https://yeunyuankuo.github.io/tags/virtualization-technologies/"}]}