[{"categories":["Go","Interview"],"contents":" I was asked this question in one of my recent software engineer job interviews, and I believe I didn’t answer it as well as I would have liked, so I wanted to write this blog to re-answer it and perhaps aid someone else who is also curious about the solution.\nIn Go articles, we often see goroutine introduced as a lightweight thread. But why is it lightweight? how lightweight?\nBefore we delve into the “lightweight” part, we need to first understand the two components in this comparison equation —Thread \u0026amp; Goroutine.\nWhat is a thread? In short, a thread is a basic unit of CPU utilization; it comprises a thread ID, a program counter, a register set, and a stack. It shares with other threads belonging to the same process its code section, data section, and other operating-system resources, such as open files and signals.\nWhat is a goroutine? In Go, a “go” statement starts the execution of a function call as an independent concurrent thread of control, or goroutine, within the same address space.\nThe expression must be a function or method call; it cannot be parenthesized. Calls of built-in functions are restricted as for expression statements.\nfunc main() { go fmt.Println(\u0026#34;Hello from another goroutine\u0026#34;) fmt.Println(\u0026#34;Hello from the main goroutine\u0026#34;) // At this point the program execution stops and all // active goroutines are killed. } The function value and parameters are evaluated as usual in the calling goroutine, but unlike with a regular call, program execution does not wait for the invoked function to complete. Instead, the function begins executing independently in a new goroutine. When the function terminates, its goroutine also terminates. If the function has any return values, they are discarded when the function completes.\nGoroutine vs. Thread Each operating system thread has a fixed-size block memory (sometimes as large as 2MB) for its stack, which is the work area where it saves the local variables of function calls that are in process or momentarily halted while another function is performed. This fixed-size stack is both too big and too small. A 2MB stack would be a tremendous waste of memory for a small goroutine that simply waits for a WaitGroup before closing a channel.\nIt is not uncommon for a Go program to generate hundreds of thousands of goroutines at once, which would be difficult to stack. Regardless of size, fixed-size stacks are not always large enough for the most complex and deeply recursive routines. Changing the fixed size can improve space efficiency and allow for the creation of more threads, or it can permit more deeply recursive algorithms, but not both.\nA goroutine, on the other hand, starts with a modest stack, typically 2KB. The stack of a goroutine, like the stack of an OS thread, maintains the local variable of active and suspended function calls, but unlike the stack of an OS thread, the stack of a goroutine is not fixed; it grows and shrinks as needed. A goroutine stack’s size limit could be as much as 1GB, which is orders of magnitude larger than a conventional fixed-size thread stack; however, few goroutines use that much.\nWrapping Up In Summary, to answer the question of why goroutine is called a lightweight thread. It’s because a goroutine starts with a stack space of 2KB which is extremely smaller and more compact than OS thread\u0026rsquo;s fixed-size stack space of 2MB. However, the goroutine’s stack space is growable and it can grow and exceed the OS thread’s 2MB fixed-stack size. So a goroutine is actually only “lightweight” in the beginning and could gradually grow “overweight” when needed!\nResources Official Go Specs The Go Programming Language — Alan A. A. Donovan and Brian W. Kernighan Operating System Concepts — Abraham Silberschatz, Greg Gagne, and Peter Baer Galvin Professor Dr. John Bell’s lecture notes for Operating Systems Goroutines are lightweight threads ","date":"August 12, 2022","hero":"/images/hero/goroutine_lightweight.jpeg","permalink":"https://yeunyuankuo.github.io/posts/go_goroutine_lightweight/","summary":"I was asked this question in one of my recent software engineer job interviews, and I believe I didn’t answer it as well as I would have liked, so I wanted to write this blog to re-answer it and perhaps aid someone else who is also curious about the solution.","tags":["Go","Golang","Goroutine","Interview"],"title":"Why is goroutine being called a “lightweight” thread?"},{"categories":["Container","Virtual Machines","Virtualization Technologies","Kubernetes"],"contents":"\n“An important sign of Kubernetes momentum is the continuing shift to production, growing from 59% in the 2020 report to 65% this year. Companies with more than 500 developers were more likely to be running all or most containerized workloads in production (78%). In our first State of Kubernetes report in 2018, less than a third (30%) reported running Kubernetes in production.”\n— State of Kubernetes 2021 Report by VMware\nIn VMware’s State of Kubernetes 2021 Report, it pointed out that there has been a distinct shift to Kubernetes in Production. More companies are choosing to run containerized workloads over other virtualization technologies like bare-metal servers and virtual machines.\nTo understand why companies favor containers over other virtualization technologies. We need to take a closer look at the 3 most common virtualization technologies on the market: Bare-metal Servers, Virtual Machines, and Containers.\nBare-metal Servers With bare-metal servers, the operating system is installed directly on the server, eliminating layers and delivering better performance. For instance, you simply install an operating system on your server hardware, then any shared libraries on top of that, and finally your application that uses those libraries, and you’d be good to go. This is how things have been for a long time.\nThe issue with this architecture is that is massively inefficient. Your hardware cost is the same whether you are running a 0% utilization or 100% utilization. All your applications are fighting for the same resources and you have to keep the versions of your library in sync with all the applications. If one program requires an updated version of the library that is incompatible with other applications operating on the same host, then you run into problems!\nVirtual Machines Virtual machine solves the problem of bare-metal server by putting a virtualization platform over the operating system. Now you’ve isolated applications and their libraries with their own full operating system into a virtual machine. This enhances usage since you can run additional virtual machines on top of the existing hardware, lowering your physical footprint significantly.\nThe disadvantage of virtual machines is that the virtualization layer is cumbersome. In the image above, you now have 4 operating systems instead of one. That means more patching, more updates, and significantly more space being taken up by the physical host. There’s also significant redundancy. You’ve installed potentially the same operating system 4 times and potentially the same library 3 times. We can do better!\nContainers By packaging code and dependencies together, containers are an abstraction for the application layer. The container runtime shares the operating system’s kernel, enabling you to create container images using file system layers. The containers are lightweight efficient and fast! Containers consume less space compared to virtual machines (container images usually take up around tens of MB in size). They can be spawned up and spawned down faster than virtual machines.\nContainers allow for better utilization of the underlying hardware. You can share libraries when necessary, but you can also isolate libraries for your applications. Containers are also highly portable. Because containers isolate software from the other layers, their codes run identically across different environments, whether it’s from compliance, staging, or all the way to production.\nSummary After understanding the differences between bare-metal servers, virtual machines, and containers, we can safely say that containers provide benefits that other virtualization technologies do not possess, such as faster software development cycles, increased resource utilization, and easier application upgrades.\nWhether your organization is one of the 65% that is already using containerized workload in production or not, the momentum behind container technology is evident!\nResources State of Kubernetes 2021 Report — VMware What is a Bare Metal Server? Docker Official Website ","date":"August 12, 2022","hero":"/images/hero/cargoship.jpeg","permalink":"https://yeunyuankuo.github.io/posts/containerization_taking_over/","summary":"An important sign of Kubernetes momentum is the continuing shift to production, growing from 59% in the 2020 report to 65% this year. Companies with more than 500 developers were more likely to be running all or most containerized workloads in production (78%). In our first State of Kubernetes report in 2018, less than a third (30%) reported running Kubernetes in production.","tags":["Container","Virtual Machines","Virtualization Technologies","Kubernetes"],"title":"Why is Containerization Taking Over?"},{"categories":["AWS","Cloud","AWS IAM"],"contents":"\nWhat is AWS IAM? In AWS, Identity and Access Management (IAM) is one of the AWS services and it is used to help users securely control access to AWS resources. Everything you do in AWS needs permission, which means that you will eventually encounter or use IAM features when building your own AWS services. IAM features include determining who is eligible to sign in, who or what has access to resources, and so on.\nIAM Terminologies Cheatsheet: IAM Resource: IAM Resources includes IAM user, IAM user group, IAM role, IAM policy, and identity provider objects.\nIAM Identity: The resource objects in IAM that are used to identify and group resources.\nIAM Entity: IAM users and IAM roles are two examples. Use AWS\u0026rsquo;s IAM resource objects for authentication.\nPrincipal: A person or application with the authority to request an AWS action or operation. The principal must be authenticated as the AWS account root user or an IAM entity in order to make requests to AWS. This includes federated users and assumed roles.\nIAM User An IAM user is an AWS entity that you create to represent a person or application that interacts with AWS. AWS users are made up of a name and credentials.\nIAM User Cheatsheet: Brand new IAM users by default has no permissions\npermission boundary can be add to a user\nEach IAM user is associated with one and only one root user\nWhen creating a IAM user, IAM username isn\u0026rsquo;t capitlization sensitive (meaning Bob equals bob)\n3 ways to identify an IAM user: Name: the name you gave when you created the user.\nAmazon Resource Name (ARN): When you need to uniquely identify a user across all of AWS, you use the ARN.\nUnique identifier: This ID is only returned when the user is created through the API, Tools for Windows PowerShell, or AWS CLI; it is not displayed in the console.\nRoot User When an AWS account is newly created, you start with a single identity that has full access to all AWS services and resources in the account. This is the AWS account\u0026rsquo;s root user identity. An IAM user with administrator privileges is not the same as the root user of an AWS account.\nRoot user Cheatsheet: One account one root user\nA root user can create at most 5000 IAM users\nAccount-wide access to all AWS services and resources\nCreate or delete an AWS account\nBest practice is to never use root user, create an IAM user and use that instead\nCredentials Different credentials are required depending on the user and how AWS resources are accessed.\nConsole password\nA password that must be entered by the user in order to access interactive sessions like the AWS Management Console.\nRoot user credential: email + password.\nIAM user credential: account ID + username + password.\nAccess keys\nAccess key is a combination of access key ID + secret key.\nTo access AWS resources programmatically via the AWS CLI, Tools for Windows PowerShell, AWS SDKs, or APIs, access keys are required.\nAn access key is associated with an IAM user.\nOne IAM user can have at most 2 access keys.\nAccess keys are unique across AWS; thus, it can be used to identify a specific user.\nSSH keys for CodeCommit\nA SSH public key that can be used to authenticate with CodeCommit (OpenSSH formatted).\nServer certificates\nCertain AWS services can be authenticated using SSL/TLS certificates. AWS Certificate Manager is used to provision, manage, and deploy server certificates (ACM).\nIf you use an IAM user\u0026rsquo;s long-term credentials in your application, avoid embedding access keys directly into the application code. As a best practice, use temporary security credentials (IAM roles) instead of long-term access keys.\nIAM Users Real-Life Scenarios Team Members\nEvery team member who needs to access AWS resources in a small organization or company will be given an IAM user account created by the company\u0026rsquo;s root user account. Each IAM user account will have its own set of credentials: username + password + accountID.\nFederated Users\nIn a larger company with multiple teams and organizations, hundreds of thousands of employees may require access to AWS resources. The \u0026ldquo;single sign-on\u0026rdquo; strategy, which leverages AD (Microsoft Active Directory) to provide employees access to AWS services after they have been confirmed, is used by the majority of enterprises.\nCross Account Users\nWhen AWS users from other accounts attempt to access your AWS resources, this is referred to as a cross account user. Accounts may come from the same or different organizations. This can be solved with IAM roles, which we will discuss in the following chapter.\nPrograms and Applications\nOften times applications will request access for your teams AWS resource through AWS APIs or AWS CLI. In this case, they need an access key (access key ID + secret key) to authenticate their requests. Use temporary security credentials (IAM roles) instead of access keys as a best practice.\nIAM User Group An IAM user group is literally what it means \u0026ndash; a group of IAM users. User groups allow you to specify permissions for multiple users, making it easier to manage those users\u0026rsquo; permissions. For example, you could create a user group called Admins and grant that group standard administrator privileges. Any user in that user group has Admins group permissions by default. You can provide administrator capabilities to a new user who joins your company by adding them to the Admins user group. If a user in your company changes jobs, instead of altering that user\u0026rsquo;s permissions, you can remove him or her from the old user groups and add him or her to the necessary new user groups.\nUser Group Cheatsheet: User groups can\u0026rsquo;t be nested; they can contain only users, not other user groups.\nA user group can have many members, and a user can belong to multiple user groups.\nThere is no default user group that includes all AWS account users by default. If you want to have a user group like that, you must create it and assign each new user to it.\nThe number and size of IAM resources in an AWS account are limited, such as the number of groups and the number of groups that a user can be a member of. More information can be found at: https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-quotas.html.\nIAM group don\u0026rsquo;t have credentials.\nA single root account can only have 300 user groups.\nThere are a maximum of 300 user groups per root account.\nResources Official AWS IAM Users Documentation\nOfficial AWS IAM User Groups Documentation\n","date":"August 1, 2022","hero":"/images/hero/iam_hero.png","permalink":"https://yeunyuankuo.github.io/posts/aws_iam/","summary":"What is AWS IAM? In AWS, Identity and Access Management (IAM) is one of the AWS services and it is used to help users securely control access to AWS resources. Everything you do in AWS needs permission, which means that you will eventually encounter or use IAM features when building your own AWS services. IAM features include determining who is eligible to sign in, who or what has access to resources, and so on.","tags":["AWS","Cloud","AWS IAM"],"title":"Learn AWS IAM - IAM Users, Groups, Credentials"},{"categories":["AWS","AWS SNS","Jest","Node.js","Testing"],"contents":"\nOutline There are a lot of jest mock examples out there, but never a clear example about Jest with AWS services (in this case, SNS). Today, in this article I will show you how to mock sns.publish with Jest and with all the code layed out and the logic explained.\nUnderstand what you\u0026rsquo;re testing How to write mock for SNS using Jest Closer look at sns.publish.mock 1. Understand what you\u0026rsquo;re testing Let\u0026rsquo;s take a look at the Node.js code that we want to write our unit test for. Inside sendMessage.js is the handler() function for the AWS Lamda that is responsible to send message to our AWS SNS whenever triggered. How this Lambda function gets triggered doesn\u0026rsquo;t matter here. All it matters is that this Lambda function will send message to our target SNS.\nInside sendMessage.js:\nconst AWS = require(\u0026#39;aws-sdk\u0026#39;) const sns = new AWS.SNS() // this handler sends message to SNS whenever called upon const handler = async event =\u0026gt; { if event.status === \u0026#34;send\u0026#34; { try { await sns.publish({ Message: \u0026#34;send this message to SNS...\u0026#34; }).promise() } catch (err) { throw err } } } module.exports = { handler } This is a fairly basic example, but enough to help us demonstrate how to mock sns.publish.\nInside handler() function, it takes in an input event and checks if event.status equals to \u0026ldquo;send\u0026rdquo;. If equals to \u0026ldquo;send\u0026rdquo; then send the hard coded message \u0026ldquo;send this message to SNS\u0026hellip;\u0026rdquo; to our target SNS.\nNow, let\u0026rsquo;s try and mock this Lambda handler() function that publishes message to SNS!\n2. How to write mock for sns.publish using Jest We will be using Jest to write our unit test and that\u0026rsquo;s it. No fancy thrid party packages needed. First, you need to create a new file named sendMessage.test.js that will contain our tests.\nInside sendMessage.test.js:\ndescribe(\u0026#39;sendMessage handler behaviors\u0026#39;, () =\u0026gt; { let mockSNS beforeAll(() =\u0026gt; { // things you want to do before all the tests starts }) afterAll(() =\u0026gt; { // things you want to do after all the tests ends }) beforeEach(() =\u0026gt; { jest.resetModules() const AWS = require(\u0026#39;aws-sdk\u0026#39;) mockSNS = { publish: jest.fn().mockReturnValue({ promise: jest.fn().mockResolvedValue({}) }) } jest.spyOn(AWS, \u0026#39;SNS\u0026#39;).mockReturnValue(mockSNS) }) test(\u0026#39;should send message to SNS\u0026#39;, async () =\u0026gt; { const handler = require(\u0026#39;./sendMessage\u0026#39;) await handler(triggerInput(\u0026#34;send\u0026#34;)) expect(mockSNS.publish).toHaveBeenCalledTimes(1) expect(mockSNS.publish).toHaveBeenCalledWith(expectedPublishContent) }) const triggerInput = (status) =\u0026gt; { status: status } const expectedPublishContent = () =\u0026gt; { Message: \u0026#34;send this message to SNS...\u0026#34; } }) Ok, let\u0026rsquo;s break down this unit test code: describe(): the testing function that we use to define our test cases and behaviors that will be carried out at different stages. This is not a required step, you can skip describe() and write test() instead. But when there are a lot of tests, it would be best to organize your test cases with describe().\nbeforeAll(): define things you want to do before all the tests starts.\nafterAll(): define things you want to do after all the tests ends.\nbeforeEach(): define things to do before each test() starts.\njest.resetModules(): this resets the module registry that stores cache. This step is useful when you want to make sure that each time your test starts with a clean state.\njest.spyOn(AWS, 'SNS'): creates a mock function like jest.fn that tracks calls coming into AWS.SNS(), and returns a mock function. Everytime before each test case, we will mock AWS.SNS() with this spyOn function. Also, remember that the const AWS = require('aws-sdk') should be defined inside beforeEach(), because we want a new AWS for each test case and not a global one (don\u0026rsquo;t require aws-sdk module outside of beforeEach()).\n.mockReturnValue(mockSNS): meaning that our mock function created with jest.spyOn(AWS, 'SNS') will return mockSNS it\u0026rsquo;s return value.\ntest(): the specific test case that we want the describe() function to run. Inside test('should send message to SNS) , it will require sendMessage.js and call the handler() that was previously defined.\nexpect(mockSNS.publish).toHaveBeenCalledTimes(1): This checks if our mocked sns.publish was called once. If called once, then retirn true. In our case, it should be true, since handler(triggerInput(\u0026quot;send\u0026quot;)) does receice an event with event.status equals to \u0026ldquo;send\u0026rdquo;, and so our lambda function should sns.publish the message we want.\nexpect(mockSNS.publish).toHaveBeenCalledWith(expectedPublishContent): this checks if the correct message was called. This basically checks if the correct message was send through sns.publish. In this case, the correct message is defined inside expectedPublishContent. This expect function will check if the message we send to mock sns is the same as what\u0026rsquo;s inside expectedPublishContent. If the same, then return true.\n3. Closer look at mockSNS.publish.mock Every mock function in Jest have a .mock property that stores the information about how the mock function was called. The same goes with our mockSNS.publish. You must be really curious about what is actually inside mockSNS.publish.mock right? Well, below is an example of the object inside mockSNS.publish.mock after running one of the test and the call have been catched by our jest.SpyOn function.\n# console.log(mockSNS.publish.mock) { \u0026#34;calls\u0026#34;: [ [ { \u0026#34;Message\u0026#34;: \u0026#34;send this message to SNS...\u0026#34; } ] ], \u0026#34;instances\u0026#34;: [ {} ], \u0026#34;invocationCallOrder\u0026#34;: [ 1 ], \u0026#34;results\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;return\u0026#34;, \u0026#34;value\u0026#34;: {} } ] } calls: an array of all the calls this mock function received\ncalls[0]: first call to the mock function\ncalls[0][0]: first arg of the first call of the mock function\ninstances: an array of objects returned by each instantiation of the mock function\ninstances[0]: the first instantiation of our mock function\nIn this case, our returned object when instantiating the mock function is empty.\ninvocationCallOrder: an array of the order of each call made to the mock function.\ninvocationCallOrder[0]: is the first call\u0026rsquo;s call order\nOur call order is 1, because our first and only call was the first to call the mock function.\nresults: an array of the return values by the mock function when each call was called\nresults[0]: return value from the first call\nIn our case, the return value for the first call is an empty object.\nResources Jest Official Documentation ","date":"June 23, 2022","hero":"/images/hero/sns_jest.png","permalink":"https://yeunyuankuo.github.io/posts/aws_sns_jest/","summary":"Outline There are a lot of jest mock examples out there, but never a clear example about Jest with AWS services (in this case, SNS). Today, in this article I will show you how to mock sns.publish with Jest and with all the code layed out and the logic explained.\nUnderstand what you\u0026rsquo;re testing How to write mock for SNS using Jest Closer look at sns.publish.mock 1. Understand what you\u0026rsquo;re testing Let\u0026rsquo;s take a look at the Node.","tags":["AWS","AWS SNS","Jest","Node.js","Testing"],"title":"AWS SNS: Mock sns.publish with Jest"},{"categories":["Git","Github","Step-by-Step Guide"],"contents":"1. Clone Target Repository Clone the remote repository code you want to your local environment. You can find the clone repo link inside the Code button drop-down.\ncd into the folder you want to clone the repository, then paste the HTTPS link and created a clone with the git clone command.\n$ git clone {HTTPS_LINK_HERE} After running the git clone command, you should see a new folder with the target repo code inside.\n2. Create a New Branch Now cd into the new folder created by the git clone command, and let’s create a new branch by using the git branch command.\n$ git branch {NEW_BRANCH_NAME} After you’ve created the branch, use the following git commands to check if your new branch has been created, and then switch to your new branch.\n# check if {NEW_BRANCH_NAME} is listed locally as your branch $ git branch # switch to new branch $ git checkout {NEW_BRANCH_NAME} 3. Push New Branch to Repository We can push our new branch to the repository with the git push command. But here we also want to set the upstream branch. Every time a new branch is created, we need to set up an upstream branch so the new branch knows which remote repository to use every time it synchronizes its commit history. This step can be achieved with the --set-upstream command.\n$ git push --set-upstream origin {NEW_BRANCH_NAME} If you didn’t set up an upstream branch and push your code, the following error code will show up. Thus, please remember to do this step before pushing your code from the new branch.\nfatal: The current branch has no upstream branch After pushing your branch to the repository, you should see your branch show up on the branches drop-down list shown in the image below. 4. Push Code Changes Now you can push code changes into the new branch you’ve just created!\n# Checkout your new branch # make changes to the code and push to new branch $ git add . $ git commit -m \u0026#34;new code commit here...\u0026#34; $ git push Resources https://opensource.com/article/19/7/create-pull-request-github https://www.geeksforgeeks.org/how-to-set-upstream-branch-on-git/ ","date":"May 29, 2022","hero":"/images/hero/git_clone.png","permalink":"https://yeunyuankuo.github.io/posts/git_create_branch/","summary":"We can push our new branch to the repository with the git push command. But here we also want to set the upstream branch. Every time a new branch is created, we need to set up an upstream branch so the new branch knows which remote repository to use every time it synchronizes its commit history. This step can be achieved with the \u0026ndash;set-upstream command.","tags":["Git","Github","branch","Step-by-Step Guide"],"title":"Step-by-Step Guide: How to create a new branch for Git repository"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://yeunyuankuo.github.io/archives/","summary":"archives","tags":null,"title":"Archives"}]